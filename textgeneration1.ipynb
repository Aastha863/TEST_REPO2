{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing dependencies\n",
    "import numpy \n",
    "import sys\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense ,Dropout, LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "#loading data and opening our input data in the form of txt file\n",
    "file = open(\"frankenstein.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization \n",
    "#standardization\n",
    "def tokenize_words(input):\n",
    "    input = input.lower()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(input)\n",
    "    filtered=filter(lambda token: token not in stopwords.words('english'),tokens)\n",
    "    return \"\".join(filtered)\n",
    "    \n",
    "processed_inputs = tokenize_words(file)\n",
    "#chars to numbers\n",
    "chars = sorted(list(set(processed_inputs)))\n",
    "char_to_num = dict((c,i) for i,c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters: 220857\n",
      "Total vocab: 42\n"
     ]
    }
   ],
   "source": [
    "#check if words to chars or chars to num (?!) has worked?\n",
    "input_len = len(processed_inputs)\n",
    "vocab_len = len(chars)\n",
    "print(\"Total number of characters:\", input_len)\n",
    "print(\"Total vocab:\",vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq length\n",
    "seq_length =100\n",
    "x_data =[]\n",
    "y_data =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns: 220757\n"
     ]
    }
   ],
   "source": [
    "#loop through the sequence\n",
    "for i in range(0, input_len - seq_length, 1):\n",
    "    in_seq = processed_inputs[i:i + seq_length]\n",
    "    out_seq = processed_inputs[i + seq_length]\n",
    "    x_data.append([char_to_num[char] for char in in_seq])\n",
    "    y_data.append(char_to_num[out_seq])\n",
    "    \n",
    "n_patterns =len(x_data)\n",
    "print (\"Total Patterns:\",n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert input sequence to np array and so on\n",
    "X = numpy.reshape(x_data, (n_patterns, seq_length, 1))\n",
    "X = X/float(vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot coding\n",
    "y = np_utils.to_categorical(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the model\n",
    "import tensorflow as tf\n",
    "tf.math.log\n",
    "model = Sequential()\n",
    "model.add(LSTM(100,input_shape=(X.shape[1], X.shape[2]), return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1],activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "import tensorflow as tf\n",
    "tf.math.log\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving weights\n",
    "filepath =\"model_weights_saved.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose = 1, save_best_only=True,mode='min')\n",
    "desired_callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0528 10:03:33.824648 140578850780992 deprecation.py:323] From /mnt/disks/user/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "220757/220757 [==============================] - 1264s 6ms/step - loss: 2.9283\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.92828, saving model to model_weights_saved.hdf5\n",
      "Epoch 2/4\n",
      "220757/220757 [==============================] - 1069s 5ms/step - loss: 2.9051\n",
      "\n",
      "Epoch 00002: loss improved from 2.92828 to 2.90511, saving model to model_weights_saved.hdf5\n",
      "Epoch 3/4\n",
      "220757/220757 [==============================] - 1062s 5ms/step - loss: 2.8691\n",
      "\n",
      "Epoch 00003: loss improved from 2.90511 to 2.86915, saving model to model_weights_saved.hdf5\n",
      "Epoch 4/4\n",
      "220757/220757 [==============================] - 1068s 5ms/step - loss: 2.8358\n",
      "\n",
      "Epoch 00004: loss improved from 2.86915 to 2.83582, saving model to model_weights_saved.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fda80934cc0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model and let it train\n",
    "tf.math.log\n",
    "tf.where\n",
    "model.fit(X,y, epochs=4, batch_size =100,callbacks=desired_callbacks)\n",
    "# here we are fitting the model which takes time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recompile model with the saved weights\n",
    "from keras.models import load_model\n",
    "filename = 'model_weights_saved.hdf5'\n",
    "model = load_model(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output of model back into characters\n",
    "num_to_char = dict((i,c) for i,c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed: \n",
      "\" n u r s e t r u e s e l d o m c a m e s e e a l t h o u g h a r d e n t l y d e s i r e d r e l i e v e s u f f e r i n g s e v e r y h u m a n c r e a t u r e w i s h p r e s e n t a g o n i e s m i \"\n"
     ]
    }
   ],
   "source": [
    "# random need to help generate\n",
    "start = numpy.random.randint(0, len(x_data)-1)\n",
    "pattern = x_data[start]\n",
    "print(\"Random Seed: \")\n",
    "print(\"\\\"\",' '.join([num_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"
     ]
    }
   ],
   "source": [
    "# generate the text\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern,(1,len(pattern), 1))\n",
    "    x = x/float(vocab_len)\n",
    "    prediction = model.predict(x,verbose=0)\n",
    "    index= numpy.argmax(prediction)\n",
    "    result = num_to_char[index]\n",
    "    seq_in = [num_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dissapointing model due to less number of epochs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
